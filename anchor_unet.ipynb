{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3LisvDshzevQ"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bdeDl5HO0QsY"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "from PIL import Image\n",
        "\n",
        "import keras\n",
        "from keras.models import Model, load_model\n",
        "from keras.layers import Conv2D, MaxPooling2D, Input, Conv2DTranspose, Concatenate, BatchNormalization, UpSampling2D\n",
        "from keras.layers import  Dropout, Activation\n",
        "from keras.optimizers import Adam, SGD\n",
        "from keras.layers import LeakyReLU\n",
        "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\n",
        "from keras import backend as K\n",
        "from keras.utils import plot_model\n",
        "import tensorflow as tf\n",
        "\n",
        "import glob\n",
        "import random\n",
        "import cv2\n",
        "from random import shuffle"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Keras version: 3.8.0\n",
        "# Tf version: 2.18.0"
      ],
      "metadata": {
        "id": "i0ytSrgdNOb2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J-ckut7NZSJd"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Params"
      ],
      "metadata": {
        "id": "2332ul3rubHP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YSkUgGAARMPh"
      },
      "outputs": [],
      "source": [
        "PROJECT_PATH = '/content/drive/MyDrive/Colab Notebooks/landmark_segmentation/' # Model is saved at the root of the project\n",
        "\n",
        "IMG_PATH = PROJECT_PATH+ 'datasets/unet/512_50/images/'\n",
        "TARGET_PATH = PROJECT_PATH + 'datasets/unet/512_50/targets/'\n",
        "\n",
        "MODEL_WEIGTH_PATH = PROJECT_PATH + '/models/unet.weights.h5'\n",
        "MODEL_BEST_WEIGHTS_PATH = PROJECT_PATH + \"/models/unet_best.weights.h5\"\n",
        "\n",
        "IMG_PATH_TEST = PROJECT_PATH + 'datasets/test_set/pign_z14/image/'\n",
        "MSK_PATH_TEST = PROJECT_PATH + 'datasets/test_set/pign_z14/mask/'\n",
        "PRED_PATH = PROJECT_PATH + 'datasets/test_set/pign_z14/pred_unet/'\n",
        "\n",
        "TILE_SIZE = (512, 512)\n",
        "\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "TRAIN_TEST_SPLIT = 0.90"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train / valid split"
      ],
      "metadata": {
        "id": "7VlSePTY_-v5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PvwbmS-YTHEZ"
      },
      "outputs": [],
      "source": [
        "all_files = os.listdir(IMG_PATH)\n",
        "shuffle(all_files)\n",
        "\n",
        "split = int(TRAIN_TEST_SPLIT * len(all_files))\n",
        "\n",
        "#split into training and validation\n",
        "train_files = all_files[0:split]\n",
        "valid_files  = all_files[split:]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Train files: {len(train_files)}\")\n",
        "print(f\"Valid files: {len(valid_files)}\")"
      ],
      "metadata": {
        "id": "A7KFtH00JBIE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tavQ2-MJ0x9E"
      },
      "source": [
        "## Generators"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P8tq55g677wp"
      },
      "outputs": [],
      "source": [
        "def image_generator(files, batch_size = 32, sz = (256, 256)):\n",
        "  '''\n",
        "  Generates batches of image and mask data for training or validation.\n",
        "\n",
        "  Args:\n",
        "      files (list): List of image filenames.\n",
        "      batch_size (int): Number of samples per batch.\n",
        "      sz (tuple): Target size for resizing images and masks.\n",
        "\n",
        "  Yields:\n",
        "      tuple: A batch of image and mask data.\n",
        "            - batch_x: NumPy array of preprocessed images.\n",
        "            - batch_y: NumPy array of preprocessed masks.\n",
        "  '''\n",
        "\n",
        "  while True:\n",
        "    #extract a random batch\n",
        "    batch = np.random.choice(files, size = batch_size)\n",
        "\n",
        "    #variables for collecting batches of inputs and outputs\n",
        "    batch_x = []\n",
        "    batch_y = []\n",
        "\n",
        "    for f in batch:\n",
        "\n",
        "        #preprocess the raw images\n",
        "        raw = Image.open(IMG_PATH + f)\n",
        "        raw = raw.resize(sz)\n",
        "        raw = np.array(raw)\n",
        "        raw = raw[:,:,0:3] # remove transparency and keep only RGB\n",
        "        batch_x.append(raw)\n",
        "\n",
        "        #preprocess the masks\n",
        "        mask = Image.open(TARGET_PATH + f'{f[:-4]}_mask.png')\n",
        "        mask = mask.convert(\"L\") # L = grayscale, was LA, remove transparence\n",
        "        mask = np.array(mask.resize(sz))\n",
        "        mask[mask == 0] = 0\n",
        "        mask[mask == 255 ] = 1\n",
        "        batch_y.append(mask)\n",
        "\n",
        "    #preprocess a batch of images and masks\n",
        "    batch_x = np.array(batch_x)/255.\n",
        "    batch_y = np.array(batch_y)\n",
        "    batch_y = np.expand_dims(batch_y,3) # add channel dimension at the end\n",
        "\n",
        "    yield (batch_x, batch_y)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_generator = image_generator(train_files, batch_size = BATCH_SIZE, sz = TILE_SIZE)\n",
        "test_generator  = image_generator(valid_files, batch_size = BATCH_SIZE, sz = TILE_SIZE)"
      ],
      "metadata": {
        "id": "pH9-VlTuAH-j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yn_bdWgIuRHD"
      },
      "outputs": [],
      "source": [
        "x, y= next(train_generator)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jnuNW20FeupL"
      },
      "outputs": [],
      "source": [
        "plt.axis('off')\n",
        "img = x[0]\n",
        "msk = y[0].squeeze()\n",
        "msk = np.stack((msk,)*3, axis=-1) # match img dimension to allow concatenation\n",
        "\n",
        "plt.imshow(np.concatenate([img, msk, img*msk], axis = 1))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## IoU"
      ],
      "metadata": {
        "id": "SKh4J4FUBXDu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def mean_iou(y_true, y_pred):\n",
        "    yt0 = tf.cast(y_true[:,:,:,0], 'float32') # Cast yt0 to float32\n",
        "    yp0 = tf.cast(y_pred[:,:,:,0] > 0.5, 'float32')\n",
        "    inter = tf.math.count_nonzero(tf.logical_and(tf.equal(yt0, 1), tf.equal(yp0, 1)))\n",
        "    union = tf.math.count_nonzero(tf.add(yt0, yp0))\n",
        "    iou = tf.where(tf.equal(union, 0), 1., tf.cast(inter/union, 'float32'))\n",
        "    return iou"
      ],
      "metadata": {
        "id": "Lo_YziAylWho"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "160g6Ex41r-2"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hONrrUbW9CM_"
      },
      "outputs": [],
      "source": [
        "def unet(sz = (256, 256, 3)):\n",
        "  x = Input(sz)\n",
        "  inputs = x\n",
        "\n",
        "  #down sampling\n",
        "  f = 8\n",
        "  layers = []\n",
        "\n",
        "  for i in range(0, 6):\n",
        "    x = Conv2D(f, 3, activation='relu', padding='same') (x)\n",
        "    x = Conv2D(f, 3, activation='relu', padding='same') (x)\n",
        "    layers.append(x)\n",
        "    x = MaxPooling2D() (x)\n",
        "    f = f*2\n",
        "  ff2 = 64\n",
        "\n",
        "  #bottleneck\n",
        "  j = len(layers) - 1\n",
        "  x = Conv2D(f, 3, activation='relu', padding='same') (x)\n",
        "  x = Conv2D(f, 3, activation='relu', padding='same') (x)\n",
        "  x = Conv2DTranspose(ff2, 2, strides=(2, 2), padding='same') (x)\n",
        "  x = Concatenate(axis=3)([x, layers[j]])\n",
        "  j = j -1\n",
        "\n",
        "  #upsampling\n",
        "  for i in range(0, 5):\n",
        "    ff2 = ff2//2\n",
        "    f = f // 2\n",
        "    x = Conv2D(f, 3, activation='relu', padding='same') (x)\n",
        "    x = Conv2D(f, 3, activation='relu', padding='same') (x)\n",
        "    x = Conv2DTranspose(ff2, 2, strides=(2, 2), padding='same') (x)\n",
        "    x = Concatenate(axis=3)([x, layers[j]])\n",
        "    j = j -1\n",
        "\n",
        "\n",
        "  #classification\n",
        "  x = Conv2D(f, 3, activation='relu', padding='same') (x)\n",
        "  x = Conv2D(f, 3, activation='relu', padding='same') (x)\n",
        "  outputs = Conv2D(1, 1, activation='sigmoid') (x)\n",
        "\n",
        "  #model creation\n",
        "  model = Model(inputs=[inputs], outputs=[outputs])\n",
        "  model.compile(optimizer = 'rmsprop', loss = 'binary_crossentropy', metrics = [mean_iou])\n",
        "\n",
        "  return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "67Fyeczk_zzh"
      },
      "outputs": [],
      "source": [
        "model = unet(sz=(TILE_SIZE[0], TILE_SIZE[1], 3))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary() # Display the model's architecture"
      ],
      "metadata": {
        "id": "QUzi5fspVqbB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t7QY8rgO1zUU"
      },
      "source": [
        "# Callbacks\n",
        "\n",
        "Simple functions to save the model at each epoch and show some predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xfqXmNuc9lWZ"
      },
      "outputs": [],
      "source": [
        "#def build_callbacks():\n",
        "#        checkpointer = ModelCheckpoint(filepath=MODEL_WEIGTH_PATH, verbose=0, save_best_only=True, save_weights_only=True)\n",
        "#        callbacks = [checkpointer, PlotLearning(), CheckPoint]\n",
        "#       return callbacks\n",
        "\n",
        "# inheritance for training process plot\n",
        "class PlotLearning(keras.callbacks.Callback):\n",
        "\n",
        "    def on_train_begin(self, logs={}):\n",
        "        self.i = 0\n",
        "        self.x = []\n",
        "        self.losses = []\n",
        "        self.val_losses = []\n",
        "        self.acc = []\n",
        "        self.val_acc = []\n",
        "        #self.fig = plt.figure()\n",
        "        self.logs = []\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs={}):\n",
        "        self.logs.append(logs)\n",
        "        self.x.append(self.i)\n",
        "        self.losses.append(logs.get('loss'))\n",
        "        self.val_losses.append(logs.get('val_loss'))\n",
        "        self.acc.append(logs.get('mean_iou'))\n",
        "        self.val_acc.append(logs.get('val_mean_iou'))\n",
        "        self.i += 1\n",
        "\n",
        "        #print info\n",
        "        print('i=',self.i,'loss=',logs.get('loss'),'val_loss=',logs.get('val_loss'),'mean_iou=',logs.get('mean_iou'),'val_mean_iou=',logs.get('val_mean_iou'))\n",
        "\n",
        "        #display sample predictions\n",
        "        for i in range(0,3):\n",
        "          #choose a random test image and preprocess\n",
        "          path = np.random.choice(valid_files)\n",
        "          raw = Image.open(IMG_PATH + path)\n",
        "          raw = np.array(raw.resize(TILE_SIZE))/255.\n",
        "          raw = raw[:,:,0:3]\n",
        "\n",
        "          #predict the mask\n",
        "          pred = model.predict(np.expand_dims(raw, 0))\n",
        "\n",
        "          #mask post-processing\n",
        "          msk  = pred.squeeze()\n",
        "          msk = np.stack((msk,)*3, axis=-1)\n",
        "          #msk[msk >= 0.5] = 1\n",
        "          #msk[msk < 0.5] = 0\n",
        "\n",
        "          #show the mask and the segmented image\n",
        "          combined = np.concatenate([raw, msk, raw* msk], axis = 1)\n",
        "          plt.axis('off')\n",
        "          plt.imshow(combined)\n",
        "          plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class CheckpointCallback(keras.callbacks.Callback):  # Callback for delayed checkpoint saving\n",
        "    def __init__(self, filepath, start_saving_epoch=20, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.filepath = filepath\n",
        "        self.start_saving_epoch = start_saving_epoch\n",
        "        self.best_val_loss = float('inf')  # Initialize best validation loss\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        current_val_loss = logs.get('val_loss')\n",
        "        if epoch + 1 >= self.start_saving_epoch and current_val_loss < self.best_val_loss:\n",
        "            self.best_val_loss = current_val_loss\n",
        "            self.model.save_weights(self.filepath)\n",
        "            print(f\"Saving weights at epoch {epoch + 1} with val_loss: {current_val_loss}\")"
      ],
      "metadata": {
        "id": "8MzKlYUJqQmg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sU6SPuVY8Mdc"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time"
      ],
      "metadata": {
        "id": "JRcyUewYj7pr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_MXGinNg9Wjj"
      },
      "outputs": [],
      "source": [
        "train_steps = len(train_files) //BATCH_SIZE\n",
        "test_steps = len(valid_files) //BATCH_SIZE\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "history = model.fit(train_generator,\n",
        "                    epochs = 150, steps_per_epoch = train_steps,validation_data = test_generator, validation_steps = test_steps,\n",
        "                    callbacks = [PlotLearning(), CheckpointCallback(MODEL_BEST_WEIGHTS_PATH, start_saving_epoch=10)],\n",
        "                    verbose = 0)\n",
        "\n",
        "end_time = time.time()\n",
        "training_time = end_time - start_time\n",
        "print(f\"Temps d'entraînement : {training_time / 60:.2f} minutes\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0O5zCKBr8OZ1"
      },
      "source": [
        "# Save model\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save_weights(MODEL_WEIGTH_PATH)"
      ],
      "metadata": {
        "id": "VfrVHBjBcAZg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Curves"
      ],
      "metadata": {
        "id": "CsD27rSzNnye"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# print hitory keys\n",
        "print(history.history.keys())"
      ],
      "metadata": {
        "id": "ESXTbFqSbkEf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# plot loss and val loss from history\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('U-net loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "# start y axe at 0\n",
        "plt.ylim(0, 0.6)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "d9CXsRJLNpDM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# plot mean iou and val_mean_iou\n",
        "plt.plot(history.history['mean_iou'])\n",
        "plt.plot(history.history['val_mean_iou'])\n",
        "plt.title('U-net mean_iou')\n",
        "plt.ylabel('mean_iou')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Bn45kW--boas"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xBIO44Dhze1t"
      },
      "source": [
        "# Testing on benchmark"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Code tiles"
      ],
      "metadata": {
        "id": "pRQB39ufSlP3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cut tiles from evaluation images\n",
        "def extract_tiles(image: Image.Image, tile_size=512, n_rows=3, n_cols=5):\n",
        "    width, height = image.size\n",
        "    stride_x = (width - tile_size) // (n_cols - 1)\n",
        "    stride_y = (height - tile_size) // (n_rows - 1)\n",
        "\n",
        "    tiles = []\n",
        "    positions = []\n",
        "\n",
        "    for row in range(n_rows):\n",
        "        for col in range(n_cols):\n",
        "            x = col * stride_x\n",
        "            y = row * stride_y\n",
        "            tile = image.crop((x, y, x + tile_size, y + tile_size))\n",
        "            tiles.append(tile)\n",
        "            positions.append((x, y))\n",
        "\n",
        "    return tiles, positions"
      ],
      "metadata": {
        "id": "kQtpeWHLRf-u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Reconstruct image from predictions\n",
        "def reconstruct_mask(tile_preds, positions, final_size=(890, 1920), tile_size=512):\n",
        "    pred_sum = np.zeros(final_size, dtype=np.float32)\n",
        "    pred_count = np.zeros(final_size, dtype=np.float32)\n",
        "\n",
        "    for pred, (x, y) in zip(tile_preds, positions):\n",
        "        h, w = pred.shape\n",
        "        pred_sum[y:y+h, x:x+w] += pred\n",
        "        pred_count[y:y+h, x:x+w] += 1.0\n",
        "\n",
        "    # Moyenne par pixel\n",
        "    averaged_pred = pred_sum / np.maximum(pred_count, 1e-6)  # évite la division par 0\n",
        "\n",
        "    return averaged_pred  # image de même taille que l’originale"
      ],
      "metadata": {
        "id": "nu6p3kC8SRTF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Make predictions"
      ],
      "metadata": {
        "id": "jxGxRlU7Sp21"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load model\n",
        "new_model = unet(sz=(TILE_SIZE[0], TILE_SIZE[1], 3))\n",
        "new_model.load_weights(MODEL_BEST_WEIGHTS_PATH)"
      ],
      "metadata": {
        "id": "Zn_SMjLgDbcg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S17rew7Vqk5e"
      },
      "outputs": [],
      "source": [
        "# for each image in the evaluation dataset, predict a mask and save it in the project benchmark folder\n",
        "EVAL_PATH = PROJECT_PATH + 'eval/base_images/'\n",
        "PRED_FOLDER = PROJECT_PATH + 'eval/pred_unet/'\n",
        "\n",
        "for f in os.listdir(EVAL_PATH):\n",
        "    # load image and create tiles\n",
        "    raw = Image.open(EVAL_PATH + f)\n",
        "    tiles, positions = extract_tiles(raw)\n",
        "\n",
        "    # For each tile, make a prediction\n",
        "    tile_preds = []\n",
        "    for tile in tiles:\n",
        "        # preprocess\n",
        "        tile = np.array(tile)/255.\n",
        "        tile = tile[:,:,0:3]\n",
        "        # predict\n",
        "        pred = new_model.predict(np.expand_dims(tile, 0), verbose=0) # add batch dim (model needs it)\n",
        "        tile_preds.append(pred.squeeze()) # remove dimensions of size 1 to keep only (512, 512)\n",
        "\n",
        "    # reconstruct final mask and save it in greyscale\n",
        "    proba = reconstruct_mask(tile_preds, positions, tile_size=TILE_SIZE[0]) # 2d array of probabilities\n",
        "    proba = (proba * 255).astype(np.uint8)\n",
        "    #proba_im = Image.fromarray(proba.astype(np.uint8), mode=\"L\")\n",
        "    #proba_im.save(PRED_FOLDER + \"proba/\" + f[:-4] + '_unet_proba.png')\n",
        "    #print(f\"Saved {PRED_FOLDER + 'proba/' + f[:-4] + '_unet_proba.png'}\")\n",
        "\n",
        "    msk = proba\n",
        "    msk[msk >= 128] = 255\n",
        "    msk[msk < 128] = 0\n",
        "    msk = Image.fromarray(msk.astype(np.uint8), mode=\"L\")\n",
        "    msk.save(PRED_FOLDER + \"pred/\" + f[:-4] + '_unet_mask.png')\n",
        "\n",
        "    #msk = np.stack((msk,)*3, axis=-1)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Combine\n",
        "\n",
        "# save combination of logits and image and show it\n",
        "combined = raw * logits\n",
        "concat = np.concatenate([raw, logits, combined], axis = 1)\n",
        "plt.axis('off')\n",
        "plt.imshow(combined)\n",
        "plt.show()\n",
        "\n",
        "#save combination\n",
        "im_combined = Image.fromarray((combined * 255).astype(np.uint8))\n",
        "im_combined.save(PRED_COMBINED_PATH + f)\n"
      ],
      "metadata": {
        "id": "0J6rsmKgVbwX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OfoO80D4uYAj"
      },
      "source": [
        "# References\n",
        "\n",
        "\n",
        "1.   http://deeplearning.net/tutorial/unet.html\n",
        "2.   https://github.com/ldenoue/keras-unet\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "sU6SPuVY8Mdc"
      ],
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}